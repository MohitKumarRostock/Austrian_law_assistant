# Auto-generated by build_embedding_index_idf_svd_npz.py
# Do not edit unless you know what you're doing.
__COMPONENTS_VERSION__ = "3"

import re
from typing import Optional

import numpy as np

try:
    from sklearn.base import BaseEstimator, TransformerMixin
except Exception:
    BaseEstimator = object
    TransformerMixin = object


_PARAGRAPH_RE = re.compile(r"ยง+")
_DIGIT_TOKEN_RE = re.compile(r"\d+")
_MULTI_SPACE_RE = re.compile(r"\s+")


def preprocess_legal_german(text: str, *, number_mode: str = "replace", number_prefix: str = "num") -> str:
    """
    Pragmatic preprocessing for German legal sentences.
    - Normalize paragraph signs to a stable token ("paragraf").
    - Handle standalone numeric tokens (default: replace with a stable token like "num12" instead of deleting).
    - Lowercase and normalize whitespace.

    number_mode:
      - "replace": replace standalone numbers with f"{number_prefix}<value>" (recommended for legal/citation retrieval)
      - "keep": keep numbers as-is (captured by char n-grams; word token_pattern may drop pure digits)
      - "remove": remove standalone numeric tokens (legacy behavior; generally not recommended for legal text)
    """
    s = str(text)
    s = _PARAGRAPH_RE.sub(" paragraf ", s)

    mode = (number_mode or "replace").strip().lower()
    if mode == "remove":
        s = _DIGIT_TOKEN_RE.sub(" ", s)
    elif mode == "replace":
        prefix = (number_prefix or "num").strip()
        if not prefix:
            prefix = "num"
        s = _DIGIT_TOKEN_RE.sub(lambda m: f" {prefix}{m.group(0)} ", s)
    elif mode == "keep":
        pass
    else:
        raise ValueError(f"Unsupported number_mode: {number_mode!r} (expected 'replace', 'keep', or 'remove').")

    s = s.lower()
    s = _MULTI_SPACE_RE.sub(" ", s).strip()
    return s


class PreprocessTransformer(BaseEstimator, TransformerMixin):
    """
    scikit-learn compatible transformer applying preprocess_legal_german.
    Top-level module class => joblib/pickle stable import path.
    """

    def __init__(self, number_mode: str = "replace", number_prefix: str = "num"):
        self.number_mode = number_mode
        self.number_prefix = number_prefix

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return [
            preprocess_legal_german(x, number_mode=self.number_mode, number_prefix=self.number_prefix)
            for x in X
        ]



class AdaptiveTruncatedSVD(BaseEstimator, TransformerMixin):
    """
    TruncatedSVD wrapper that clips n_components at fit-time based on X shape.
    Prevents crashes if requested dim > (n_features-1) or (n_samples-1).

    Exposes:
      - n_components_ (effective)
      - explained_variance_ratio_
      - components_ (from underlying TruncatedSVD)
    """
    def __init__(
        self,
        n_components: int = 512,
        *,
        n_iter: int = 15,
        random_state: int = 42,
        algorithm: str = "randomized",
    ):
        self.n_components = int(n_components)
        self.n_iter = int(n_iter)
        self.random_state = int(random_state)
        self.algorithm = str(algorithm)

        self.n_components_: Optional[int] = None
        self.model_ = None
        self.explained_variance_ratio_ = None
        self.components_ = None

    def fit(self, X, y=None):
        from sklearn.decomposition import TruncatedSVD

        n_samples = int(getattr(X, "shape", [0, 0])[0])
        n_features = int(getattr(X, "shape", [0, 0])[1])

        # Practical constraint: <= min(n_samples, n_features) - 1
        max_allowed = min(n_samples, n_features) - 1
        if max_allowed < 1:
            raise ValueError("Cannot fit TruncatedSVD: shape=({},{})".format(n_samples, n_features))

        n_comp = min(int(self.n_components), int(max_allowed))

        self.n_components_ = int(n_comp)
        self.model_ = TruncatedSVD(
            n_components=self.n_components_,
            algorithm=self.algorithm,
            n_iter=self.n_iter,
            random_state=self.random_state,
        )
        self.model_.fit(X)

        self.explained_variance_ratio_ = getattr(self.model_, "explained_variance_ratio_", None)
        self.components_ = getattr(self.model_, "components_", None)
        return self

    def transform(self, X):
        if self.model_ is None:
            raise RuntimeError("AdaptiveTruncatedSVD is not fitted.")
        return self.model_.transform(X)

    def fit_transform(self, X, y=None):
        return self.fit(X, y=y).transform(X)
